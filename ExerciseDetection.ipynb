{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2c7df2-9ddf-4303-a971-2dc307ce9e55",
   "metadata": {},
   "source": [
    "\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e050feb-b3c6-4c66-a353-0616109d4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a4731-2e23-42dd-841b-56595b207173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "pio.templates.default = 'plotly_dark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3a94f-bee7-4585-a8e4-40fcf9a64af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder , MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score ,auc ,roc_auc_score , confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637e58b-c252-4c75-bc3a-95226d218f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de2a9e-c7fb-4377-a217-3cae7cd59bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254571a-02b6-44a6-bf57-41ab7edc08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import logging\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances ,plot_contour\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a6165-364d-4b14-91d0-1bda70838627",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdb248-6bdc-48d2-aba7-59e1d68f9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file_to_same_location(zip_path):\n",
    "\n",
    "    extract_to = os.path.dirname(zip_path)\n",
    " \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "       \n",
    "        zip_ref.extractall(extract_to)\n",
    "        print('Extraction Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1b4c1-f584-4c55-9bf7-8cc86430b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = 'archive (2).zip'\n",
    "unzip_file_to_same_location(zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea8cd8-f127-4ac0-95f5-34dc0cb42257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exercise_angles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f25e93-f5e9-4c98-b932-a58878e1bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_observations, num_features = df.shape\n",
    "print(f\"Number of observations: {num_observations}\")\n",
    "print(f\"Number of features: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0535345-a2d9-49b6-9283-132882138319",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_counts = df['Side'].value_counts()\n",
    "print(\"Value counts for 'Side' column:\")\n",
    "print(side_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09930022-69bf-442e-a344-49f59466840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Side',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610f58f-8e0e-4114-86a8-e6098f89d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2431e58-edd1-4ea0-b9cb-e6cc003eaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "\n",
    "colors = ['#2d288f', '#5342a5', '#735ebb', '#927bd1', '#b199e8', \n",
    "          '#f1cbf9', '#dca7f7', '#bf85f8', '#9666fa', '#554cff']\n",
    "\n",
    "fig = make_subplots(rows=2, cols=5, subplot_titles=[col.replace('_', ' ') for col in numeric_columns])\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    row = (i // 5) + 1\n",
    "    col_pos = (i % 5) + 1\n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=df[col], marker_color=colors[i], name=col.replace('_', ' ') , nbinsx=20, showlegend=False),\n",
    "        row=row, col=col_pos\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=500, width=1100, title_text=\"Histograms for all body joint angles\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e604678-2775-49a4-9281-b92bb2e4ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df.melt(id_vars='Label', var_name='body joint angle', value_name='Values')\n",
    "colors = ['#288f11', '#00b79d', '#7fd3e8', '#00a3ff', '#8c3aff']\n",
    "       \n",
    "\n",
    "df_melted['body joint angle'] = df_melted['body joint angle'].str.replace('_', ' ')\n",
    "fig = px.box(df_melted, x='Label', y='Values', color='Label', \n",
    "             facet_col='body joint angle', facet_col_wrap=2,\n",
    "             color_discrete_sequence=colors)\n",
    "\n",
    "fig.update_layout(height=1000, width=1200, title=\"Box Plot for body joint angle by labels\")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915affdd-6bef-4a09-9a82-799a0a2e798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Label'] = label_encoder.fit_transform(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6aaef-e887-45b1-bcb0-715f6e15b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, label_column):\n",
    "\n",
    "    \n",
    "    X = df.drop(columns=[label_column])\n",
    "    y = df[label_column]\n",
    "\n",
    "    first_four_columns = X.columns[:5] \n",
    "    last_four_columns = X.columns[5:10]  \n",
    "\n",
    "    transformers = [\n",
    "        ('standard_scaler', StandardScaler(), first_four_columns),\n",
    "        ('minmax_scaler', MinMaxScaler(), last_four_columns),\n",
    "       \n",
    "    ]\n",
    "\n",
    "    column_transformer = ColumnTransformer(transformers)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_train_scaled = column_transformer.fit_transform(X_train)\n",
    "    X_test_scaled = column_transformer.transform(X_test)\n",
    "\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=np.concatenate([first_four_columns, last_four_columns]))\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=np.concatenate([first_four_columns, last_four_columns]))\n",
    "\n",
    "    return X_train_scaled,y_train, X_test_scaled,  y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837eaf39-3791-4d66-91d6-c070fbdf9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = preprocess_data(df, 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00f240-64fa-47c0-942c-a37e23a9c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(X_train, y_train, X_test, y_test, random_state=42):\n",
    "\n",
    "    classifiers = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=random_state),\n",
    "        'Decision Tree': DecisionTreeClassifier(random_state=random_state),\n",
    "        'Random Forest': RandomForestClassifier(random_state=random_state),\n",
    "        'Support Vector Machine': SVC(random_state=random_state),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=random_state),\n",
    "        'Perceptron': Perceptron(random_state=random_state),\n",
    "        'Quadratic Discriminant Analysis': QuadraticDiscriminantAnalysis(),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=random_state),\n",
    "        'LightGBM': LGBMClassifier(random_state=random_state,verbosity=-1),\n",
    "        'CatBoost': CatBoostClassifier(silent=True, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "        test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "        results.append({'Model': name, 'Train Accuracy': train_acc, 'Test Accuracy': test_acc})\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values('Test Accuracy',ascending=False).reset_index(drop=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e4c55-7481-4f89-8a39-e846e13e165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = train_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b950f-4c8e-43bc-948a-e7ee2271fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9720d-5afc-46c0-afb1-dd36ffc84901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lightgbm(X_train_scaled, y_train,X_test_scaled, y_test):\n",
    "    \n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'objective': 'multiclass',\n",
    "            'num_class': len(set(y_train)), \n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "            'verbosity': -1,\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 70, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 6, 20),  # -1 means no limit\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.1, 1.0),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 20, 400),\n",
    "            'subsample': trial.suggest_float('subsample', 0.2, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 0.5),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 100),\n",
    "      \n",
    "        }\n",
    "\n",
    "        model = LGBMClassifier(**param, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    sampler = TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction='maximize',sampler=sampler)\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085cc27-0189-44b9-8935-b90389621537",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optimize_lightgbm(X_train,y_train, X_test, y_test)\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58731-3c1f-489e-b318-367a8f9abb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1, subplot_titles=(\"Optimization History\", \"Parameter Importances\"))\n",
    "\n",
    "scatter_color = 'blue'  \n",
    "line_color = 'green'    \n",
    "fig1 = plot_optimization_history(study)\n",
    "\n",
    "\n",
    "for trace in fig1.data:\n",
    "    if isinstance(trace, go.Scatter) and 'markers' in trace.mode:  \n",
    "        trace.update(marker=dict(color=scatter_color))  \n",
    "    elif isinstance(trace, go.Scatter) and 'lines' in trace.mode: \n",
    "        trace.update(line=dict(color=line_color))  \n",
    "\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "fig2 = plot_param_importances(study)\n",
    "\n",
    "bar_color = 'darkblue'  \n",
    "\n",
    "for trace in fig2.data:\n",
    "    if isinstance(trace, go.Bar):  \n",
    "        trace.update(marker=dict(color=bar_color))  \n",
    "    trace.showlegend = False  \n",
    "    fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Optuna Study Results\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557f9f9-a2d0-475b-80b3-0954666fb9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hyperparameter_contour(study, param1, param2, row, col):\n",
    "    x = np.array([trial.params[param1] for trial in study.trials])\n",
    "    y = np.array([trial.params[param2] for trial in study.trials])\n",
    "    z = np.array([trial.value for trial in study.trials])\n",
    "\n",
    "    contour = go.Contour(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        colorscale='Blues',\n",
    "        colorbar=dict(title=\"Accuracy\"),\n",
    "        contours=dict(\n",
    "            start=np.min(z),\n",
    "            end=np.max(z),\n",
    "            size=(np.max(z) - np.min(z)) / 20,\n",
    "            showlabels=False\n",
    "        ),\n",
    "        name=f\"{param1} vs {param2}\"\n",
    "    )\n",
    "\n",
    "    return contour\n",
    "\n",
    "def plot_all_hyperparameter_contours(study):\n",
    "    fig = make_subplots(rows=2, cols=2, subplot_titles=(\n",
    "        \"num_leaves vs max_depth\",\n",
    "        \"n_estimators vs learning_rate\",\n",
    "        \"subsample vs colsample_bytree\",\n",
    "        \"reg_alpha vs reg_lambda\"\n",
    "    ))\n",
    "\n",
    "    hyperparams = [\n",
    "        ('num_leaves', 'max_depth', 1, 1),\n",
    "        ('n_estimators', 'learning_rate', 1, 2),\n",
    "        ('subsample', 'colsample_bytree', 2, 1),\n",
    "        ('reg_alpha', 'reg_lambda', 2, 2)\n",
    "    ]\n",
    "\n",
    "    for param1, param2, row, col in hyperparams:\n",
    "        contour = plot_hyperparameter_contour(study, param1, param2, row, col)\n",
    "        fig.add_trace(contour, row=row, col=col)\n",
    "\n",
    "    fig.update_layout(title=\"Hyperparameter Contour Plots\", height=800, width=1000)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe63625-1fcb-4e9b-8171-505ace5da097",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_hyperparameter_contours(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dc0b7-f234-4493-ba80-073f0a7324dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "print(f\"Re-training LightGBM...\")\n",
    "model = LGBMClassifier(**best_params, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.5f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495027c3-a7b6-4f28-9c87-83accc85192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(confusion_matrix_test, \n",
    "                     index=label_encoder.inverse_transform(range(confusion_matrix_test.shape[0])), \n",
    "                     columns=label_encoder.inverse_transform(range(confusion_matrix_test.shape[1])))\n",
    "\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=cm_df.values,\n",
    "    x=cm_df.columns.tolist(),\n",
    "    y=cm_df.index.tolist(),\n",
    "    colorscale='Blues',\n",
    "  \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Confusion Matrix Heatmap',\n",
    "    xaxis_title='Predicted Labels',\n",
    "    yaxis_title='True Labels',\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d5c67-7d8f-4bc4-b2e0-62d23894a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "importance_df['Normalized Importance'] = importance_df['Importance'] / importance_df['Importance'].sum()\n",
    "\n",
    "importance_df = importance_df.sort_values(by='Normalized Importance', ascending=True)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=importance_df['Normalized Importance'],\n",
    "    y=importance_df['Feature'],\n",
    "    orientation='h',\n",
    "    marker=dict(color='darkblue')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Normalized Feature Importance',\n",
    "    xaxis_title='Normalized Importance Score',\n",
    "    yaxis_title='Features',\n",
    "    showlegend=False  \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Kaggle)",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
